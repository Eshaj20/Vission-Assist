 VisionAssist â€“ AI-Powered Object Detection for Low-Light Environments  ğŸš€

ğŸ“Œ Overview

VisionAssist is an AI-based object detection system designed for low-light environments. It leverages YOLOv8 and YOLOv11 models, fine-tuned on the ExDark dataset, to accurately detect objects in challenging lighting conditions. The system integrates Raspberry Pi, ultrasonic sensors, and servo motors for real-time distance and direction estimation, enhancing accessibility and navigation assistance.

ğŸ”¥ Features

âœ… Low-Light Object Detection â€“ Uses YOLOv8 & YOLOv11 fine-tuned on the ExDark dataset.âœ… Real-Time Processing â€“ Runs efficiently on Raspberry Pi with optimized deep-learning models.âœ… Distance & Direction Estimation â€“ Uses ultrasonic sensors & servo motors to provide object location feedback.âœ… Hardware Integration â€“ Seamless connection with sensors for a complete assistive solution.

   ğŸ›  Hardware Components

ğŸ”¹ Raspberry Pi â€“ Runs the object detection model.
ğŸ”¹ Ultrasonic Sensor â€“ Measures object distance.
ğŸ”¹ Servo Motor â€“ Adjusts the sensorâ€™s direction to scan the surroundings.

ğŸ–¥ Software & Tools Used

ğŸ Python â€“ Core programming language.

ğŸ” YOLOv8 & YOLOv11 â€“ Object detection models.

ğŸ“¸ OpenCV â€“ Image processing and real-time video handling.

ğŸ§  PyTorch/TensorFlow â€“ Deep learning framework.

ğŸŒ GitHub â€“ Version control and project collaboration.


   âš™ Installation & Setup

1ï¸âƒ£ Clone the Repository

              git clone https://github.com/Eshaj20/VissionAssist.git
              cd VisionAssist

2ï¸âƒ£ Install Dependencies

              pip install -r requirements.txt

3ï¸âƒ£ Run the Object Detection Model

             python vision_assist.py



   ğŸ¯ Usage

ğŸ”¹ Start the system â€“ The camera captures real-time frames.ğŸ”¹ Object Detection â€“ The model detects objects and provides bounding boxes.ğŸ”¹ Distance Estimation â€“ The ultrasonic sensor measures object distance.ğŸ”¹ Direction Assistance â€“ Servo motors adjust angles for better coverage.

   ğŸ“Š Results & Performance

![image](https://github.com/user-attachments/assets/44521981-4f45-40c9-8040-0e5420aca444)
ğŸ“Œ Mean Average Precision (mAP): 38% (Add actual performance metrics)ğŸ“Œ Precision: 0.81ğŸ“Œ Recall: 0.74

ğŸ“Œ Distance Measurement Accuracy:

![Screenshot 2025-02-21 184316](https://github.com/user-attachments/assets/0d8babf5-75ad-44fb-b3d9-b23a9f6c4bff)

ğŸ”¹ Average Error (m): 0.062, 0.058, 0.072, 0.11, 0.16
ğŸ”¹ Standard Deviation: 0.07, 0.06, 0.10, 0.12, 0.28

ğŸ“Œ Accuracy in Low-Light: 81.4% (Performance comparison before & after fine-tuning)

   ğŸš€ Future Improvements

ğŸ”¹ Edge AI Optimization â€“ Improve real-time processing on Raspberry Pi.
ğŸ”¹ Face Recognition Integration â€“ (Previously attempted but faced hardware limitations.
)ğŸ”¹ Voice Assistance â€“ Convert detections into audio feedback for visually impaired users.

